stages:
  - pre_check
  - static_analyzers
  - build_openocd
  - run_test_pipelines
  - build_nuttx
  - test_host
  - test_nuttx
  - results
  - deploy
  - pre_release
  - release_stage1
  - release_submit
  - update_idf_tools

image: $CI_DOCKER_REGISTRY/openocd-ci-env:1

default:
  interruptible: true
  retry:
    max: 2
    when: runner_system_failure
    exit_codes: 75

variables:

  #
  # System environment

  # Common parameters for the 'make' during CI tests
  MAKEFLAGS: "-j4 --no-keep-going"

  GCOV_BUILD_OPTS: ""

  # OpenOCD configuration options
  OPENOCD_CONFIGURE_OPTS: "--disable-doxygen-html --enable-remote-bitbang"

  # GitHub Tool options
  GITHUB_USER: "${GH_USER}"
  GITHUB_REPO: "${GH_REPO}"
  GITHUB_TOKEN: "${GH_TOKEN}"

  #
  # CI settings

  # GIT_STRATEGY is not defined here, an option from "CI / CD Settings"- "General pipelines" is used.
  GIT_SUBMODULE_STRATEGY: none

  #
  # Customization of jobs

  DIST_ART_DIR: "dist"
  DIST_INSTALLED_DIR: "${CI_PROJECT_NAME}"
  ARCHIVE_TOOL: "tar czf"
  ARCHIVE_EXT: "tar.gz"
  RELEASE_DESC: "New release"

# prefix should be like a $CI_PROJECT_NAME, but we cannot use variable here
.release_tag_filter: &release_tag_filter
  only:
    - /^v[0-9].*$/
    - /^openocd-esp32-.*$/

.release_binaries: &release_binaries
  needs:
    - job: build_linux
    - job: build_linux_armhf
    - job: build_linux_armel
    - job: build_linux_arm64
    - job: build_windows_win32
    - job: build_windows_win64
    - job: macos_codesign

.release_submit_action: &release_submit_action
  image: espressif/github-hub:2
  when: manual
  allow_failure: true
  before_script:
    - set -o errexit; set -o pipefail; set -o nounset
    - test "${DEBUG_SHELL:-''}" = "1" && set -x
    - git remote remove github || true
    - git remote add github ${GH_REPO_HTTPS}
  variables:
    GIT_STRATEGY: fetch
    GH_REL_TAG: ${CI_COMMIT_TAG}
    SHA256_FILE: openocd-esp32-${CI_COMMIT_TAG}-checksum.sha256

before_script:
  - set -o errexit; set -o pipefail; set -o nounset
  - test "${DEBUG_SHELL:-''}" = "1" && set -x

pipeline_variables:
  stage: pre_check
  tags:
    - build
  variables:
    GIT_STRATEGY: none
  script:
    - >
      echo "TRIGGERED_BY_GDB_PIPELINE_BRANCH=${TRIGGERED_BY_GDB_PIPELINE_BRANCH:-}" >> variables.env;
      if [[ ! -z ${TRIGGERED_BY_GDB_PIPELINE_BRANCH:-} ]]; then
        echo "CI_FULL_RUN=0" >> variables.env;
      elif [[ $CI_PIPELINE_SOURCE != "push" || $CI_COMMIT_BRANCH == "master" ]]; then
        echo "CI_FULL_RUN=1" >> variables.env;
      else
        api_call="https://${CI_SERVER_HOST}:${CI_SERVER_PORT}/api/v4/projects/67/merge_requests?source_branch=${CI_COMMIT_REF_NAME}&state=opened";
        echo "${api_call}";
        OPEN_MR=$(curl --header "PRIVATE-TOKEN: ${ESPCI_TOKEN}" "${api_call}");
        echo $OPEN_MR;
        ready=$(echo "$OPEN_MR" | python3 -c "import json; x=json.loads(input()); print(1 if len(x) and 'labels' in x[0] and 'ready_to_merge' in x[0]['labels'] else 0)");
        echo "CI_FULL_RUN=${ready}" >> variables.env;
      fi
  artifacts:
    reports:
      dotenv: variables.env

macos_codesign:
  stage: pre_release
  <<: *release_tag_filter
  when: on_success
  resource_group: macos_codesign
  tags: [ "darwin", "codesign" ]
  # list all jobs that produces macos distros
  needs: [build_macos, build_macos_arm64]
  artifacts:
    paths:
      - ${DIST_ART_DIR}
  variables:
    # directory with distro archives
    DIST_ART_DIR: dist
    # command to unarchive distro
    UNARCHIVE_TOOL: "tar xzf"
    # URL to macos codesign repo
    NOTARIZATION_SCRIPTS_GIT: "${CI_SERVER_PROTOCOL}://gitlab-ci-token:${CI_JOB_TOKEN}@${CI_SERVER_HOST}:${CI_SERVER_PORT}/espressif/macos_codesign_notarization.git"
  script:
    - git clone -q --depth=1 ${NOTARIZATION_SCRIPTS_GIT} -b ${CI_COMMIT_REF_NAME} ||
      git clone -q --depth=1 ${NOTARIZATION_SCRIPTS_GIT}
    - ./macos_codesign_notarization/run.sh

release_tag_draft:
  stage: release_stage1
  tags: [ "amd64", "internet" ]
  <<: *release_tag_filter
  <<: *release_submit_action
  <<: *release_binaries
  script:
    - git remote remove github || true
    - git remote add github ${GH_REPO_HTTPS}
    - hub release show ${GH_REL_TAG} || { echo "Please create a release on GitHub with ${GH_REL_TAG} tag at first"; exit 1; }
    # List of archives
    - DIST_DIR=dist
    - FILES=$(find ${DIST_DIR} -name dist_name_\* -exec cat {} \+)
    - cd ${DIST_DIR}
    - ls -l $FILES
    # Generate checksum file
    - >
      for n in $FILES; do
        sz=$(stat -c%s "${n}") >> ${SHA256_FILE};
        printf "# %s: %s bytes\n" "${n}" "${sz}" >> ${SHA256_FILE};
        sha256sum -b "${n}" >> ${SHA256_FILE};
      done
    # Append FILES with checksum file
    - FILES=$(echo -e "${FILES}\n${SHA256_FILE}")
    - ls -l $FILES
    # Upload archives
    - for n in ${FILES}; do hub release edit -m "" -a "${n}" "${GH_REL_TAG}"; done

Release_tag_submit:
  stage: release_submit
  tags: [ "amd64", "internet" ]
  <<: *release_tag_filter
  <<: *release_submit_action
  dependencies: []
  script:
    - hub release create -m "${RELEASE_DESC}" ${GH_REL_TAG}

Pre-Release_tag_submit:
  stage: release_submit
  tags: [ "amd64", "internet" ]
  <<: *release_tag_filter
  <<: *release_submit_action
  dependencies: []
  script:
    - hub release create --prerelease -m "${RELEASE_DESC}" ${GH_REL_TAG}

Delete_tag_release:
  stage: release_submit
  tags: [ "amd64", "internet" ]
  <<: *release_tag_filter
  <<: *release_submit_action
  dependencies: []
  script:
    - hub release delete ${GH_REL_TAG}

test_idf_examples:
  stage: pre_release
  allow_failure: true
  rules:
    - if: $CI_PIPELINE_SOURCE == "schedule" && $SCHEDULE_TYPE == "run_idf_tests"
      when: always
    - if: $CI_COMMIT_BRANCH == "master"
      when: manual
  variables:
    PARENT_PIPELINE_ID: $CI_PIPELINE_ID
  trigger:
    include: .gitlab/ci/idf-examples.yml
    strategy: depend
  needs:
    - job: build_linux_armhf
    - job: build_linux_arm64

create_reports:
  stage: results
  tags:
    - build
  artifacts:
    paths:
      - dist/lcov_all_report.tar.gz
      - cov_infos/metrics.txt
      - cov_infos/cobertura.xml
    reports:
      metrics: cov_infos/metrics.txt
      coverage_report:
        coverage_format: cobertura
        path: cov_infos/cobertura.xml
      junit:
        - "*/results/*.xml"
    when: always
    expire_in: 1 week
    when: always
    expire_in: 1 week
  needs:
    - job: 5.1.x_run_test_pipeline
    - job: 5.2.x_run_test_pipeline
    - job: 5.3.x_run_test_pipeline
    - job: 5.4.x_run_test_pipeline
    - job: 5.5.x_run_test_pipeline
    - job: master_run_test_pipeline
    # NuttX
    - job: test_nuttx_esp32
    - job: test_nuttx_esp32s2
    - job: test_nuttx_esp32s3
    - job: test_nuttx_esp32c3
    - job: test_nuttx_esp32c6
    - job: test_nuttx_esp32h2
  when: always
  script:
    # Fetch artifacts from downstream
    - >
      api_call="https://${CI_SERVER_HOST}:${CI_SERVER_PORT}/api/v4/projects/67/pipelines/${CI_PIPELINE_ID}/bridges";
      echo "${api_call}";
      BRIDGES=$(curl --header "PRIVATE-TOKEN: ${ESPCI_TOKEN}" "${api_call}");
      CHILD_IDS=$(echo "$BRIDGES" | python3 -c "import json; x=json.loads(input()); print(' '.join(str(y['downstream_pipeline']['id']) for y in x if y['name'].endswith('_run_test_pipeline')))");
      for child in $CHILD_IDS; do
        api_call="https://${CI_SERVER_HOST}:${CI_SERVER_PORT}/api/v4/projects/67/pipelines/${child}/jobs";
        echo "${api_call}";
        JOBS=$(curl --header "PRIVATE-TOKEN: ${ESPCI_TOKEN}" "${api_call}");
        TEST_IDS=$(echo "$JOBS" | python3 -c "import json; x=json.loads(input()); print(' '.join(str(y['id']) for y in x if y['name'].startswith('tests_') and y['status'] != 'skipped'))");
        for test in $TEST_IDS; do
          api_call="https://${CI_SERVER_HOST}:${CI_SERVER_PORT}/api/v4/projects/67/jobs/${test}/artifacts";
          echo "${api_call}";
          curl --header "PRIVATE-TOKEN: ${ESPCI_TOKEN}" "${api_call}" -o artifacts.zip;
          unzip artifacts.zip || echo "No valid artifacts for ${test}";
        done;
      done;
    - mkdir -p cov_infos
    - mkdir -p dist
    # Below lines copies all .info files into cov_infos folder
    - >
      folder_list=$(ls -d build_test_app*);
      for each_folder in $folder_list ;
      do
      lcov --gcov-tool ${PWD}/${each_folder}/esp_cov_files/gcov --capture --directory ${each_folder}/esp_cov_files --output-file ${each_folder}/${each_folder}.info;
      done
    - cp `find . -wholename "./build_test_app*/*.info" -size +0` cov_infos
    - ls -la cov_infos/
    # Creating a html report of coverage files.
    - genhtml --ignore-errors source cov_infos/*.info -o lcov_html_report/
    - tar czf dist/lcov_all_report.tar.gz lcov_html_report/
    # Below lines collecting all coverage file names with '-a' flag for lcov merge command.
    - >
      FILES="" ;
      for each_file in cov_infos/*.info ;
      do
      FILES+=" -a ${each_file}" ;
      done
    - lcov ${FILES} -o cov_infos/merged.info
    # Line in below creates a txt file from merged coverage file which includes coverage percentages.
    - lcov --rc lcov_list_width=150 --list cov_infos/merged.info > cov_infos/metrics_input.txt
    - python3 tools/list_to_metrics.py --file cov_infos/metrics_input.txt
    - lcov_cobertura cov_infos/merged.info -o cov_infos/cobertura.xml

mr_auto_approve:
  stage: results
  tags:
    - build
  dependencies:
    - pipeline_variables
  when: on_success
  script:
    - >
      if [[ -z ${TRIGGERED_BY_GDB_PIPELINE_BRANCH:-} &&  $CI_PIPELINE_SOURCE == "push" && $CI_COMMIT_BRANCH != "master" && $CI_FULL_RUN == "1" ]]; then
        api_call="https://${CI_SERVER_HOST}:${CI_SERVER_PORT}/api/v4/projects/67/merge_requests?source_branch=${CI_COMMIT_REF_NAME}&state=opened";
        echo "${api_call}";
        OPEN_MR=$(curl --header "PRIVATE-TOKEN: ${ESPCI_TOKEN}" "${api_call}");
        echo $OPEN_MR;
        iid=$(echo "$OPEN_MR" | python3 -c "import json; x=json.loads(input()); print(x[0]['iid'] if len(x) and 'iid' in x[0] else 0)");
        target=$(echo "$OPEN_MR" | python3 -c "import json; x=json.loads(input()); print(x[0]['target_branch'] if len(x) and 'target_branch' in x[0] else '')");
        if [[ $iid != "0" && $target == "master" ]]; then
          api_call="https://${CI_SERVER_HOST}:${CI_SERVER_PORT}/api/v4/projects/67/merge_requests/${iid}/approve";
          echo "${api_call}";
          curl --request POST --header "PRIVATE-TOKEN: ${ESPCI_TOKEN}" "${api_call}";
        fi
      fi

update_idf_tools:
  stage: update_idf_tools
  when: manual
  allow_failure: true
  <<: *release_tag_filter
  variables:
    TOOL_NAME: openocd
    TOOL_MEMBERS: openocd-esp32
    TOOL_VERSION: ${CI_COMMIT_TAG}
    TOOL_SHA256_URL: https://github.com/espressif/openocd-esp32/releases/download/${CI_COMMIT_TAG}/openocd-esp32-${CI_COMMIT_TAG}-checksum.sha256
  trigger:
    project: idf/idf-tools-updater
    strategy: depend

include:
  - '.gitlab/ci/util.yml'
  - '.gitlab/ci/build.yml'
  - '.gitlab/ci/test-template.yml'
  - '.gitlab/ci/pre-check.yml'
  - '.gitlab/ci/nuttx.yml'
  - '.gitlab/ci/host-test.yml'
  - '.gitlab/ci/run-pipeline.yml'
